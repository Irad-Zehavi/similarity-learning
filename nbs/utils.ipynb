{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from fastai.vision.all import *\n",
    "from torchvision.models.feature_extraction import create_feature_extractor\n",
    "\n",
    "from fastai_datasets.all import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def as_percentage(x, ndigits=2):\n",
    "    return f'{round(x * 100, ndigits=ndigits)}%'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def cut_model_by_name(model, cut):\n",
    "    graph = create_feature_extractor(model, [cut])\n",
    "    base_forward = graph.forward\n",
    "    graph.forward = lambda *args, **kwargs: base_forward(*args, **kwargs)[cut]\n",
    "    return graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = resnet34()\n",
    "body = cut_model_by_name(classifier, 'avgpool')\n",
    "test(body, 'avgpool', hasattr)\n",
    "assert not hasattr(body, 'fc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class MLP(Module):\n",
    "    def __init__(self, logits: Optional[int], hidden_depth=5, hidden_width=512, features_dim=None):\n",
    "        super().__init__()\n",
    "        features_dim = features_dim or hidden_width\n",
    "\n",
    "        def generate_hidden_layers():\n",
    "            if hidden_depth == 0:\n",
    "                return\n",
    "            if hidden_depth >= 2:\n",
    "                yield nn.LazyLinear(hidden_width)\n",
    "                yield nn.ReLU()\n",
    "                for _ in range(hidden_depth - 2):\n",
    "                    yield nn.Linear(hidden_width, hidden_width)\n",
    "                    yield nn.ReLU()\n",
    "            yield nn.LazyLinear(features_dim)\n",
    "\n",
    "        self.hidden_layers = nn.Sequential(*generate_hidden_layers())\n",
    "        self.logits = nn.LazyLinear(logits) if logits else None\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.flatten(start_dim=1)\n",
    "        x = self.hidden_layers(x)\n",
    "        if self.logits:\n",
    "            x = self.logits(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "from fastai.vision.all import *\n",
    "\n",
    "class Threshold(nn.Module):\n",
    "    \"\"\"Classifies 1D inputs into 2 classes, based on whether they surpass a threshold or not\"\"\"\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "        self.t = nn.Parameter(torch.zeros(1))\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x - self.t\n",
    "        return torch.stack([x, -x], dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = Threshold()\n",
    "with torch.no_grad():\n",
    "    threshold.t[0] = 3\n",
    "\n",
    "test_eq(threshold(torch.arange(10)).argmax(1), torch.tensor([1]*3+[0]*7))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since this is such a simple model, we can fit it to data without iterative optimization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@patch\n",
    "def fit(self: Threshold, x, y):\n",
    "    \"\"\"Picks a threshold that maximizes the empirical accuracy\"\"\"\n",
    "    with torch.no_grad():\n",
    "        def accuracy_for_threshold(t):\n",
    "            self.t[0] = t\n",
    "            return accuracy(self(x), y)\n",
    "\n",
    "        threshold_candidates = np.arange(0.0, 4.0, 0.01)\n",
    "        self.t[0], accuracy_score = max(((t, accuracy_for_threshold(t)) for t in threshold_candidates),\n",
    "                                                key=lambda p: p[1])\n",
    "\n",
    "        return self.t.item(), accuracy_score.item()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = Threshold()\n",
    "x = torch.randint(high=10, size=(100,))\n",
    "chosen_threshold, _ = threshold.fit(x, x < 3)\n",
    "\n",
    "test_close(chosen_threshold, 3, eps=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from abc import ABC, abstractmethod\n",
    "from dataclasses import dataclass\n",
    "    \n",
    "\n",
    "@dataclass\n",
    "class Experiment(ABC):\n",
    "    \"\"\"\n",
    "    Represents some ML experiment, where we which to run a process (e.g. training a model) multiple times (e.g. on different datasets, or to account for stochasticity) and aggregate the results\n",
    "    \"\"\"\n",
    "    model: nn.Module\n",
    "    data: List[Datasets]\n",
    "    seed: int = 0\n",
    "    \n",
    "    def run(self):\n",
    "        return ExperimentResults(self._run())\n",
    "\n",
    "    @return_list\n",
    "    def _run(self):\n",
    "        if self.seed is not None:\n",
    "            set_seed(self.seed, reproducible=True)\n",
    "\n",
    "        initial_state_dict = deepcopy(self.model.state_dict())\n",
    "\n",
    "        splits = master_bar(self.data)\n",
    "        for i, split in enumerate(splits):\n",
    "            self.dls = split.dls()\n",
    "            yield self.iteration()\n",
    "            self.model.load_state_dict(initial_state_dict)\n",
    "\n",
    "    @abstractmethod\n",
    "    def iteration(self):\n",
    "        pass\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class ExperimentResults(object):\n",
    "    \"\"\"\n",
    "    Results of an `Experiment`\n",
    "    \"\"\"\n",
    "    stats: List[Any]\n",
    "\n",
    "    @property\n",
    "    def collated_stats(self):\n",
    "        return default_collate(self.stats)\n",
    "\n",
    "    @property\n",
    "    def mean_stats(self):\n",
    "        return self.collated_stats.map(lambda t: t.mean().item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class LinearMNIST(Experiment):\n",
    "    def iteration(self):\n",
    "        learn = Learner(self.dls, self.model, metrics=accuracy)\n",
    "        learn.fit(1)\n",
    "        return learn.validate()\n",
    "    \n",
    "res = LinearMNIST(model=nn.Sequential(nn.Flatten(), nn.Linear(3*28*28, 2)),\n",
    "                  data=[TinyMNIST() for _ in range(3)]).run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(#2) [0.13420510292053223,0.9785407781600952],\n",
       " (#2) [0.13059759140014648,0.9799714088439941],\n",
       " (#2) [0.1380815953016281,0.9799714088439941]]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#2) [tensor([0.1342, 0.1306, 0.1381], dtype=torch.float64),tensor([0.9785, 0.9800, 0.9800], dtype=torch.float64)]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.collated_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#2) [0.1342947632074356,0.9794945319493612]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.mean_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
